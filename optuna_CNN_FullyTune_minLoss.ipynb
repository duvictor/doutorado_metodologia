{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3750,
     "status": "ok",
     "timestamp": 1611030957765,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "587U3hHFYjnA",
    "outputId": "05b084a1-cf3b-4a87-84be-e90df326c673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (4.3.0)\n",
      "Requirement already satisfied: PyYAML in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: alembic in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (1.7.3)\n",
      "Requirement already satisfied: tqdm in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: numpy in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: cliff in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: colorlog in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: importlib-metadata in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: importlib-resources in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from alembic->optuna) (5.9.0)\n",
      "Requirement already satisfied: Mako in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from alembic->optuna) (1.2.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: autopage>=0.4.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: colorama in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyreadline3 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: attrs>=16.3.0 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages (from Mako->alembic->optuna) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12400\\3160452846.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'pip install optuna'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0moptuna\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\PycharmProjects\\pythonProject\\optuna.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchsummary\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msummary\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;31m# !pip install optuna\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "# from torchsummary import summary\n",
    "\n",
    "!pip install optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3740,
     "status": "ok",
     "timestamp": 1611030957768,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "IO7PB0saYwVq"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")  ##'cuda' or 'cpu'\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10   #CLASSES = 10 for cifar10 and 100 for cifar100\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3737,
     "status": "ok",
     "timestamp": 1611030957770,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "_zx8QaqLY1NK"
   },
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    output_channels1 = trial.suggest_int(name=\"filters_1\", low=32, high=64, step=32)\n",
    "    layers.append(nn.Conv2d(in_channels=3, out_channels=output_channels1, kernel_size=3, stride=1))\n",
    "    layers.append(nn.BatchNorm2d(output_channels1))\n",
    "    layers.append(nn.ReLU())\n",
    "    p1 = trial.suggest_float(name=\"dropout_l\", low=0.2, high=0.4)\n",
    "    layers.append(nn.Dropout(p1))\n",
    "\n",
    "    output_channels2 = trial.suggest_int(name=\"filters_2\", low=64, high=128, step=32)\n",
    "    layers.append(nn.Conv2d(in_channels=output_channels1, out_channels=output_channels2, kernel_size=3, stride=2))\n",
    "    layers.append(nn.BatchNorm2d(output_channels2))\n",
    "    layers.append(nn.ReLU())\n",
    "    p2 = trial.suggest_float(name=\"dropout_2\", low=0.2, high=0.4)\n",
    "    layers.append(nn.Dropout(p2))\n",
    "\n",
    "    layers.append(nn.Conv2d(in_channels=output_channels2, out_channels=128, kernel_size=3, stride=2))\n",
    "    layers.append(nn.BatchNorm2d(128))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Dropout(0.2))\n",
    "\n",
    "    layers.append(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2))\n",
    "    layers.append(nn.BatchNorm2d(256))\n",
    "    layers.append(nn.ReLU())\n",
    "    \n",
    "    layers.append(nn.Flatten())\n",
    "    output_units1 = trial.suggest_int(name=\"linear_1\", low=128, high=512, step=128)\n",
    "    layers.append(nn.Linear(256*2*2, output_units1))  #output size found by printing the model detail using summary in torchsummary \n",
    "    layers.append(nn.Dropout(0.2))\n",
    "    layers.append(nn.Linear(output_units1, CLASSES))  #CLASSES = 10 for cifar10 and 100 for cifar100\n",
    "    #cross entropy loss used as loss function, therefore no softmax layer here\n",
    "\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3735,
     "status": "ok",
     "timestamp": 1611030957772,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "n4apuxgZuHbB"
   },
   "outputs": [],
   "source": [
    "def get_cifar10():\n",
    "    # Load cifar10 dataset.\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=DIR, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    \n",
    "    #split training data into training-80% and validation-20%\n",
    "    train_set, val_set = torch.utils.data.random_split(trainset, [int(0.8*len(trainset)), int(0.2*len(trainset))])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCHSIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "    \n",
    "    valid_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCHSIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    testset = torchvision.datasets.CIFAR10(root=DIR, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=BATCHSIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    \"\"\"\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3732,
     "status": "ok",
     "timestamp": 1611030957773,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "vLM6cAdcvcod"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]) #for hp tuning\n",
    "    #optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True) #for hp tuning\n",
    "    #lr = 0.001\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    CEloss = nn.CrossEntropyLoss()  ## this loss object must be used the loop. Directly using nn.CrossEntropyLoss() gives error\n",
    "\n",
    "    # Get the MNIST dataset.\n",
    "    train_loader, valid_loader = get_cifar10()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = CEloss(output, target)  ## used cross entropy loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            val_loss_batch = 0\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                #data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)  ## for mnist\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)  ## for cifar 10 and 100\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                val_loss_batch += CEloss(output, target).item()  ## used cross entropy loss\n",
    "\n",
    "        #accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "        val_loss_epoch = val_loss_batch / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        #trial.report(accuracy, epoch)\n",
    "        trial.report(val_loss_epoch, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss_epoch #accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291991,
     "status": "ok",
     "timestamp": 1611031246036,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "00dcwGRRweud",
    "outputId": "459a0b76-a6ac-46e1-ee88-246ea737982c"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "    study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "    study.optimize(objective, n_trials=30, timeout=600)\n",
    "\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291990,
     "status": "ok",
     "timestamp": 1611031246039,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "_YAn0L5k5i-F",
    "outputId": "c0a8163a-b852-417e-dec8-528658733d07"
   },
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 292624,
     "status": "ok",
     "timestamp": 1611031246675,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "HBBRqyRr5mU2",
    "outputId": "02f08c74-4df4-47f7-c1b4-c803d2e8f1ca"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 293348,
     "status": "ok",
     "timestamp": 1611031247402,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "Z0sDjm3U5ooR",
    "outputId": "ff6b3b8b-0306-469a-e6bc-f440467537c6"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study) ## this is important to figure out which hp is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 293345,
     "status": "ok",
     "timestamp": 1611031247403,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "cL7VIquW5xN-",
    "outputId": "428de4b6-457d-421c-f8af-df99ff5808f8"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)   ## this gives a clear picture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 294017,
     "status": "ok",
     "timestamp": 1611031248079,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "WpXM9lSe6GBg",
    "outputId": "9c10842e-b2c0-4be7-fcbe-a349ef561172"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 294015,
     "status": "ok",
     "timestamp": 1611031248081,
     "user": {
      "displayName": "shakti wadekar",
      "photoUrl": "",
      "userId": "08441724570566508972"
     },
     "user_tz": 300
    },
    "id": "nQss4aRjfUme",
    "outputId": "ae592248-baae-4da7-f639-ac2bf2bfe32b"
   },
   "outputs": [],
   "source": [
    "# SKIP THIS\n",
    "#### used for testing output sizes of layers in the model\n",
    "#****important: only change the input filter to maintain the output size of each layer\n",
    "\"\"\"\n",
    "model = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1)\n",
    "    ,nn.BatchNorm2d(32)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Dropout(0.2)\n",
    "    ,nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3, stride=2)\n",
    "    ,nn.BatchNorm2d(128) #this must be same as the out_channel of the previous layer\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Dropout(0.2)\n",
    "    ,nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2)\n",
    "    ,nn.BatchNorm2d(128)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Dropout(0.2)\n",
    "    ,nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2)\n",
    "    ,nn.BatchNorm2d(256)\n",
    "    ,nn.ReLU()\n",
    "    ,nn.Flatten()\n",
    "    ,nn.Linear(256*2*2, 500)  #output size found by printing the model detail using summary in torchsummary \n",
    "    ,nn.Dropout(0.2)\n",
    "    ,nn.Linear(500, CLASSES))  #CLASSES = 10 for cifar10 and 100 for cifar100\n",
    "\n",
    "print(summary(model,(3,32,32)))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP617ZzqQ69NPC3P0MG10d1",
   "collapsed_sections": [],
   "name": "optuna_CNN_FullyTune_minLoss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}