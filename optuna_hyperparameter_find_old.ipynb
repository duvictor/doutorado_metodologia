{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/optuna/optuna.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "responsavel por executar o teste com optuna\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "# from torchsummary import summary\n",
    "import numpy as np\n",
    "# !pip install optuna\n",
    "import optuna\n",
    "import cufflinks\n",
    "import plotly\n",
    "import matplotlib as plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Argumentos necessários para que a rede possa executar\n",
    "### nChannel = 100 - Quantidade de neuronios usados nas camadas da deep learning de segmentação.\n",
    "### maxIter = 50 - Quantidade de iterações de treinamento.\n",
    "### minLabels = 3 - Quantidade mínima de segmentos/regiões que a rede deverá criar para cada imagem.\n",
    "### lr = 0.1 - Taxa de aprendizado utilizado na deep learning.\n",
    "### nConv = 3 - Quantidade de camadas convolucionais no terceiro bloco da deep learning.\n",
    "### visualize - Responsável por exibir imagens durante a execução do treinamento\n",
    "### stepsize_sim = 1 - Tamanho do passo na loss de similaridade\n",
    "### stepsize_con = 1 - Tamanho do passo na loss de continuidade\n",
    "\n",
    "# DEVICE = torch.device(\"cuda\")  ##'cuda' or 'cpu'\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda == False:\n",
    "    DEVICE = torch.device(\"cuda\")  ##'cuda' or 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "\n",
    "    layers = []\n",
    "    nChannel = trial.suggest_int(name=\"nChannel\", low=15, high=150, step=15)\n",
    "    nConv = trial.suggest_int(name=\"nConv\", low=1, high=9, step=2)\n",
    "\n",
    "    # CNN model\n",
    "    class MyNet(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(MyNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(input_dim, nChannel, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(nChannel)\n",
    "            self.conv2 = nn.ModuleList()\n",
    "            self.bn2 = nn.ModuleList()\n",
    "            for i in range(nConv - 1):\n",
    "                self.conv2.append(nn.Conv2d(nChannel, nChannel, kernel_size=3, stride=1, padding=1))\n",
    "                self.bn2.append(nn.BatchNorm2d(nChannel))\n",
    "            self.conv3 = nn.Conv2d(nChannel, nChannel, kernel_size=1, stride=1, padding=0)\n",
    "            self.bn3 = nn.BatchNorm2d(nChannel)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.bn1(x)\n",
    "\n",
    "            for i in range(nConv - 1):\n",
    "                x = self.conv2[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = self.bn2[i](x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            return x\n",
    "\n",
    "    model = MyNet(1)\n",
    "    .to(DEVICE)\n",
    "    return model, nChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pixels_hu_2(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16),\n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "\n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "\n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "\n",
    "    image += np.int16(intercept)\n",
    "\n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def read_dicom_file(filepath):\n",
    "    slices = [pydicom.read_file(filepath + '/' + s) for s in os.listdir(filepath)]\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "\n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "    patient1_hu_scans = get_pixels_hu_2(slices)\n",
    "\n",
    "    # images = resample3d(patient1_hu_scans)\n",
    "    #plot_3d(images)\n",
    "    # return images\n",
    "\n",
    "    return patient1_hu_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def getDataExame():\n",
    "    folder_dcm = r\"E:\\PycharmProjects\\pythonProject\\exame\\CQ500CT257\\Unknown Study\\CT 0.625mm\"\n",
    "    exame = np.array([read_dicom_file(folder_dcm)])\n",
    "    exame1 = exame.reshape(256, 512, 512)\n",
    "    return exame1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "\n",
    "    # Generate the model.\n",
    "    model, nChannel_2 = define_model(trial)\n",
    "    print(model)\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "    maxIter = trial.suggest_int(name=\"maxIter\", low=5, high=15, step=5)\n",
    "    # Generate the optimizers.\n",
    "    stepsize_sim = trial.suggest_float(name=\"stepsize_sim\", low=1, high=2, step=0.5)\n",
    "    stepsize_con = trial.suggest_float(name=\"stepsize_con\", low=1, high=2, step=0.5)\n",
    "    minLabels = trial.suggest_int(name=\"minLabels\", low=3, high=6, step=1)\n",
    "    # nChannel_2 = trial.suggest_int(name=\"nChannel_2\", low=15, high=150, step=15)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])  # for hp tuning\n",
    "    # optimizer_name = \"Adam\"\n",
    "    lr = trial.suggest_float(name=\"lr\", low=0.001, high=0.1, log=True)\n",
    "#     momentum = trial.suggest_float(name=\"momentum\", low=0.9, high=0.99, log=True)\n",
    "    # lr = 0.001\n",
    "#     optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, momentum=0.9)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    # similarity loss definition\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # scribble loss definition\n",
    "    loss_fn_scr = torch.nn.CrossEntropyLoss()\n",
    "    # continuity loss definition\n",
    "    loss_hpy = torch.nn.L1Loss(size_average=True)\n",
    "    loss_hpz = torch.nn.L1Loss(size_average=True)\n",
    "\n",
    "    # criando objetivos, ou seja, criando tensores compostos de zeros\n",
    "    # esses tensores serão utilizados como objetivos para poder reduzir os valores de perda no treinamento\n",
    "    # não supervisionado das redes neurais\n",
    "    HPy_target = torch.zeros(512 - 1, 512, nChannel_2)\n",
    "    HPz_target = torch.zeros(512, 512 - 1, nChannel_2)\n",
    "\n",
    "    if use_cuda:\n",
    "        HPy_target = HPy_target.cuda()\n",
    "        HPz_target = HPz_target.cuda()\n",
    "\n",
    "    # instanciando o algoritmo de gradiente descendente\n",
    "    # com parâmetros de learning rate e momentum\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "\n",
    "    # Get the dataset.\n",
    "\n",
    "    exame1 = getDataExame()\n",
    "\n",
    "\n",
    "\n",
    "    for batch_idx in range(maxIter):\n",
    "        model.train()\n",
    "        parou = False\n",
    "        for slice in range(256):\n",
    "            data1 = exame1[slice, :, :]\n",
    "            data = torch.from_numpy(data1.reshape(1, 1, 512, 512).astype('float32'))\n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "            data = Variable(data)\n",
    "\n",
    "            # forwarding\n",
    "            optimizer.zero_grad()\n",
    "            output1 = model(data)[0]\n",
    "            output = output1.permute(1, 2, 0).contiguous().view(-1, nChannel_2)\n",
    "\n",
    "            # plt.imshow(output.data.cpu().numpy())\n",
    "            # plt.show()\n",
    "\n",
    "            outputHP = output.reshape((data.shape[2], data.shape[3], nChannel_2))\n",
    "            HPy = outputHP[1:, :, :] - outputHP[0:-1, :, :]\n",
    "            HPz = outputHP[:, 1:, :] - outputHP[:, 0:-1, :]\n",
    "            lhpy = loss_hpy(HPy, HPy_target)\n",
    "            lhpz = loss_hpz(HPz, HPz_target)\n",
    "\n",
    "            ignore, target = torch.max(output, 1)\n",
    "            im_target = target.data.cpu().numpy()\n",
    "\n",
    "            # plt.imshow(im_target.reshape(191, 194))\n",
    "            # plt.show()\n",
    "\n",
    "            nLabels = len(np.unique(im_target))\n",
    "\n",
    "            loss = stepsize_sim * loss_fn(output, target) + stepsize_con * (lhpy + lhpz)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # torch.save(model.state_dict(), 'results/model.pth')\n",
    "            # torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "\n",
    "#             print(batch_idx, '/', maxIter, '|', ' label num :', nLabels, ' | loss :', loss.item(), ' | slice :', slice)\n",
    "            if nLabels <= minLabels:\n",
    "#                 trial.report(batch_idx, loss)\n",
    "#                 trial.report(batch_idx, nLabels)\n",
    "                print(\"nLabels\", nLabels, \"reached minLabels\", minLabels, \".\")\n",
    "                parou = True\n",
    "                break\n",
    "        \n",
    "        if parou:\n",
    "            break\n",
    "        trial.report(loss, nLabels)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return loss  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #study = optuna.create_study(direction=\"maximize\")  # 'maximize' because objective function is returning accuracy\n",
    "    study = optuna.create_study(direction=\"minimize\")  # 'minimize' because objective function is returning loss\n",
    "    study.optimize(objective, n_trials=200)\n",
    "\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    optuna.visualization.plot_param_importances(study)  ## this is important to figure out which hp is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    optuna.visualization.plot_slice(study)  ## this gives a clear picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}