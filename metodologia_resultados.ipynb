{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Responsável por mostrar o funcionamento de baixo nível da metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação obrigatória das bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13960\\3906654990.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# from skimage import measure\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmpl_toolkits\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmplot3d\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mart3d\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPoly3DCollection\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mnibabel\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnb\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;31m#conversor utilizado para realizar a leitura dos dicoms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mdicom_to_nifti\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconverter\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn.init\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "# from skimage import measure\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import nibabel as nb\n",
    "#conversor utilizado para realizar a leitura dos dicoms\n",
    "from dicom_to_nifti import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Unsupervised Segmentation')\n",
    "parser.add_argument('--scribble', action='store_true', default=False, help='use scribbles')\n",
    "parser.add_argument('--nChannel', metavar='N', default=100, type=int, help='number of channels')\n",
    "parser.add_argument('--maxIter', metavar='T', default=50, type=int, help='number of maximum iterations')\n",
    "parser.add_argument('--minLabels', metavar='minL', default=8, type=int, help='minimum number of labels')\n",
    "parser.add_argument('--lr', metavar='LR', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--nConv', metavar='M', default=3, type=int, help='number of convolutional layers')\n",
    "parser.add_argument('--stepsize_con', metavar='CON', default=1, type=float, help='step size for continuity loss')\n",
    "parser.add_argument('--stepsize_scr', metavar='SCR', default=1, type=float, help='step size for scribble loss')\n",
    "parser.add_argument('--visualize', metavar='1 or 0', default=1, type=int, help='visualization flag')\n",
    "# parser.add_argument('--input', metavar='FILENAME', default=r'D:\\Users\\paulo\\PycharmProjects\\pytorch-unsupervised-segmentation-tip\\imagens\\3.png', help='input image file name', required=False)\n",
    "parser.add_argument('--input', metavar='FILENAME',\n",
    "                    default=r'E:\\PycharmProjects\\pythonProject\\imagens\\Dsc32909.jpg',\n",
    "                    help='input image file name', required=False)\n",
    "parser.add_argument('--stepsize_sim', metavar='SIM', default=1, type=float, help='step size for similarity loss', required=False)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotarHistograma(exame):\n",
    "    # plt.hist(exame.flatten(), bins=80, color='c')\n",
    "    plt.hist(exame.flatten(), color='c')\n",
    "    plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dcm = r\"E:\\PycharmProjects\\pythonProject\\exame\\CQ500CT257\\Unknown Study\\CT 0.625mm\"\n",
    "nifti_file = r\"E:\\PycharmProjects\\pythonProject\\exame\\CQ500CT257.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = converter(folder_dcm, nifti_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'exame_linha_210_'+ str(args.minLabels) + '.nii.gz'\n",
    "img = nb.Nifti1Image(vol.T, np.eye(4))  \n",
    "nb.save(img, os.path.join('build', fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exame1 = vol.reshape(256,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotarHistograma(exame1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, args.nChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(args.nChannel)\n",
    "        self.conv2 = nn.ModuleList()\n",
    "        self.bn2 = nn.ModuleList()\n",
    "        for i in range(args.nConv - 1):\n",
    "            self.conv2.append(nn.Conv2d(args.nChannel, args.nChannel, kernel_size=3, stride=1, padding=1))\n",
    "            self.bn2.append(nn.BatchNorm2d(args.nChannel))\n",
    "        self.conv3 = nn.Conv2d(args.nChannel, args.nChannel, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(args.nChannel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        for i in range(args.nConv - 1):\n",
    "            x = self.conv2[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.bn2[i](x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(np.array([exame1.astype('float32') / 255.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    data = data.cuda()\n",
    "data = Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet(1)\n",
    "print(model)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity loss definition\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# continuity loss definition\n",
    "loss_hpy = torch.nn.L1Loss(size_average=True)\n",
    "loss_hpz = torch.nn.L1Loss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPy_target = torch.zeros(512 - 1, 512, args.nChannel)\n",
    "HPz_target = torch.zeros(512, 512 - 1, args.nChannel)\n",
    "if use_cuda:\n",
    "    HPy_target = HPy_target.cuda()\n",
    "    HPz_target = HPz_target.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_colours = np.random.randint(255, size=(100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parou = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx in range(args.maxIter):\n",
    "    if parou:\n",
    "        break\n",
    "    for slice in range(256):\n",
    "        data1 = exame1[slice, :, :]\n",
    "        data = torch.from_numpy(data1.reshape(1,1,512,512).astype('float32'))\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        data = Variable(data)\n",
    "\n",
    "\n",
    "        # forwarding\n",
    "        optimizer.zero_grad()\n",
    "        output1 = model(data)[0]\n",
    "\n",
    "        # plt.imshow(output1[0,:,:].data.cpu().numpy())\n",
    "        # plt.show()\n",
    "\n",
    "        output = output1.permute(1, 2, 0).contiguous().view(-1, args.nChannel)\n",
    "\n",
    "        # plt.imshow(output.data.cpu().numpy())\n",
    "        # plt.show()\n",
    "\n",
    "        outputHP = output.reshape((data.shape[2], data.shape[3], args.nChannel))\n",
    "        HPy = outputHP[1:, :, :] - outputHP[0:-1, :, :]\n",
    "        HPz = outputHP[:, 1:, :] - outputHP[:, 0:-1, :]\n",
    "\n",
    "        # continuity loss definition\n",
    "        lhpy = loss_hpy(HPy, HPy_target)\n",
    "        lhpz = loss_hpz(HPz, HPz_target)\n",
    "\n",
    "        ignore, target = torch.max(output, 1)\n",
    "        im_target = target.data.cpu().numpy()\n",
    "\n",
    "        # plt.imshow(im_target.reshape(191, 194))\n",
    "        # plt.show()\n",
    "\n",
    "        nLabels = len(np.unique(im_target))\n",
    "\n",
    "\n",
    "        if args.visualize:\n",
    "            im_target_rgb = np.array([label_colours[c % args.nChannel] for c in im_target])\n",
    "            im_target_rgb = im_target_rgb.reshape(512,512,3).astype(np.uint8)\n",
    "\n",
    "            im_target_rgb = cv2.resize(im_target_rgb, (600, 600))\n",
    "            data2 = cv2.resize(data1, (600, 600))\n",
    "            cv2.imshow(\"output\", im_target_rgb)\n",
    "            cv2.imshow(\"original\", data2)\n",
    "            cv2.waitKey(10)\n",
    "        loss = args.stepsize_sim * loss_fn(output, target) + args.stepsize_con * (lhpy + lhpz)\n",
    "       \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         torch.save(model.state_dict(), 'results/model.pth')\n",
    "#         torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "\n",
    "        print(batch_idx, '/', args.maxIter, '|', ' label num :', nLabels, ' | loss :', loss.item())\n",
    "\n",
    "        if nLabels <= args.minLabels:\n",
    "            print(\"nLabels\", nLabels, \"reached minLabels\", args.minLabels, \".\")\n",
    "            parou = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dcm = r\"E:\\PycharmProjects\\pythonProject\\exame\\CQ500CT420\\Unknown Study\\CT 0.625mm\"\n",
    "nifti_file = r\"E:\\PycharmProjects\\pythonProject\\exame\\CQ500CT420.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exame_teste = converter(folder_dcm, nifti_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exame1_teste = exame_teste.reshape(256,512,512)\n",
    "nifti_teste = np.ones((256, 512, 512), dtype=np.uint8) # dummy data in numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in range(256):\n",
    "    data1 = exame1_teste[slice, :, :]\n",
    "    data_teste = torch.from_numpy(data1.reshape(1, 1, 512, 512).astype('float32'))\n",
    "    if use_cuda:\n",
    "        data_teste = data_teste.cuda()\n",
    "    data_teste = Variable(data_teste)\n",
    "    output_teste = model(data_teste)[0]\n",
    "    output = output_teste.permute(1, 2, 0).contiguous().view(-1, args.nChannel)\n",
    "    ignore, target = torch.max(output, 1)\n",
    "    im_target = target.data.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    im_target_rgb = np.array([label_colours[c % args.nChannel] for c in im_target])\n",
    "    im_target_rgb = im_target_rgb.reshape(512, 512, 3).astype(np.uint8)\n",
    "\n",
    "    nifti_teste[slice, :, :] = im_target.reshape(512, 512).astype(np.uint8)\n",
    "\n",
    "    im_target_rgb = cv2.resize(im_target_rgb, (600, 600))\n",
    "    data2 = cv2.resize(data1, (600, 600))\n",
    "    cv2.imshow(\"output\", im_target_rgb)\n",
    "    cv2.imshow(\"original\", data2)\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'teste_segmentation_'+ str(args.minLabels) + '.nii.gz'\n",
    "img = nb.Nifti1Image(nifti_teste.T, np.eye(4))  # Save axis for data (just identity)\n",
    "img.header.get_xyzt_units()\n",
    "img.to_filename(os.path.join('build',fileName))  # Save as NiBabel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}